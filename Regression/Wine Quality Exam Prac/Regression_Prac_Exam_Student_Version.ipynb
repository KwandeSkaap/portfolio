{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Practical Assessment\n",
    "This assessment is for determining how much you have learnt in the past sprint, the results of which will be used to determine how EDSA can best prepare you for the working world. This assessment consists of and practical questions in Regression.\n",
    "\n",
    "The answers for this test will be input into Athena as Multiple Choice Questions. The questions are included in this notebook and are made **bold** and numbered according to the Athena Questions.\n",
    "\n",
    "As this is a time-constrained assessment, if you are struggling with a question, rather move on to a task you are better prepared to answer rather than spending unnecessary time on one question.\n",
    "\n",
    "**_Good Luck!_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Honour Code\n",
    "I **YOUR NAME, YOUR SURNAME**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).  \n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "\n",
    "Download the Notebook and data files here: https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/Machine_Learning_Assessment.zip\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data\n",
    "For this assessment we will be using a dataset about the quality of wine. Read in the data and take a look at it.\n",
    "\n",
    "**Note** the feature we will be predicting is quality, i.e. the label is quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0     0            7.0              0.27         0.36            20.7   \n",
       "1     0            6.3              0.30         0.34             1.6   \n",
       "2     0            8.1              0.28         0.40             6.9   \n",
       "3     0            7.2              0.23         0.32             8.5   \n",
       "4     0            7.2              0.23         0.32             8.5   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "\n",
       "   sulphates  alcohol  quality  \n",
       "0       0.45      8.8        6  \n",
       "1       0.49      9.5        6  \n",
       "2       0.44     10.1        6  \n",
       "3       0.40      9.9        6  \n",
       "4       0.40      9.9        6  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Data pre-processing\n",
    "\n",
    "Write a function to pre-process the data so that we can run it through the classifier. The function should:\n",
    "* Split the data into features and labels\n",
    "* Standardise the features using sklearn's ```StandardScaler```\n",
    "* Split the data into 75% training and 25% testing data\n",
    "* Set random_state to equal 16 for this internal method\n",
    "* If there are any NAN values, fill them with zeros\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a dataframe as input.\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
    "\n",
    "**Note: be sure to pay attention to the test size and random state you use as the following questions assume you split the data correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type 0.0\n",
      "fixed acidity 0.0015391719255040787\n",
      "volatile acidity 0.001231337540403263\n",
      "citric acid 0.00046175157765122367\n",
      "residual sugar 0.00030783438510081576\n",
      "chlorides 0.00030783438510081576\n",
      "free sulfur dioxide 0.0\n",
      "total sulfur dioxide 0.0\n",
      "density 0.0\n",
      "pH 0.0013852547329536709\n",
      "sulphates 0.0006156687702016315\n",
      "alcohol 0.0\n",
      "quality 0.0\n"
     ]
    }
   ],
   "source": [
    "#question 11\n",
    "for x in df:\n",
    "    print(x, df[x].isna().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(df):\n",
    "\n",
    "    #your code here\n",
    "    \n",
    "    df['pH'] = df['pH'].fillna(0)\n",
    "    df['sulphates'] = df['sulphates'].fillna(0)\n",
    "    df['chlorides'] = df['chlorides'].fillna(0)\n",
    "    df['residual sugar'] = df['residual sugar'].fillna(0)\n",
    "    df['citric acid'] = df['citric acid'].fillna(0)\n",
    "    df['volatile acidity'] = df['volatile acidity'].fillna(0)\n",
    "    df['fixed acidity'] = df['fixed acidity'].fillna(0)\n",
    "    y = df['quality'].values\n",
    "    df.pop('quality')\n",
    "    x = df.values\n",
    "    \n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    x = sc.fit_transform(x)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 16)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.75018984 -0.00412596  0.12564592  0.97278786 -0.70253493  0.51297929\n",
      " -0.36766435 -1.26942219  0.21456681  0.92881824  2.13682458  0.42611996]\n",
      "7\n",
      "[-0.57136659 -0.30574457 -0.54115965 -0.12776549  1.33614333 -0.37168026\n",
      "  1.26631947  0.30531117  0.18121615 -0.91820734  0.32886116 -0.07697409]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "((X_train, y_train), (X_test, y_test)) = data_preprocess(df)\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_test[3])\n",
    "print(y_test[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.75018984 -0.01279612  0.12343265  0.97285518 -0.70302881  0.51268878\n",
      " -0.36766435 -1.26942219  0.21456681  1.13061485  2.14299274  0.42611996]\n",
      "7\n",
      "[-0.57136659 -0.32152108 -0.54511832 -0.12892086  1.33606028 -0.37231913\n",
      "  1.26631947  0.30531117  0.18121615 -1.17289356  0.32795025 -0.07697409]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_test[3])\n",
    "print(y_test[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8282787380653501"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question11\n",
    "X_train[12][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.17191842758365714\n"
     ]
    }
   ],
   "source": [
    "#Question 12\n",
    "print(X_test[12, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#Question 13\n",
    "print(y_train[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#Question 14\n",
    "print(y_test[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "\n",
    "```python\n",
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_test[3])\n",
    "print(y_test[3])\n",
    "\n",
    "[ 1.75018984 -0.00412596  0.12564592  0.97278786 -0.70253493  0.51297929\n",
    " -0.36766435 -1.26942219  0.21456681  0.92881824  2.13682458  0.42611996]\n",
    "7\n",
    "[-0.57136659 -0.30574457 -0.54115965 -0.12776549  1.33614333 -0.37168026\n",
    "  1.26631947  0.30531117  0.18121615 -0.91820734  0.32886116 -0.07697409]\n",
    "6\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11. What is the result of printing out the 6th column and the 13th row of X_train?**\n",
    "\n",
    "**Q12. What is the result of printing out 6th column and the 13th row of X_test?**\n",
    "\n",
    "**Q13. What is the result of printing out the 16th row y_train?**\n",
    "\n",
    "**Q14. What is the result of printing out the 16th row of y_test?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Train Linear Regression Model\n",
    "\n",
    "Since this dataset is about predicting quality, which ranges from 1 to 10, lets try fit the data to a regression model and see how well that performs.\n",
    "\n",
    "Fit a model using sklearn's `LinearRegression` class with its default parameters. Write a function that will take as input `(X_train, y_train)` that we created previously, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `LinearRegression` model.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    \n",
    "    #your code here\n",
    "    global reg\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.821226664268554"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 15\n",
    "\n",
    "train_model(X_train, y_train).intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2561262855781778"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 16\n",
    "train_model(X_train, y_train).coef_[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15. What is the result of printing out ***model.intercept_*** for the fitted model rounded to 3 decimal places?**\n",
    "\n",
    "**Q16. What is the result of printing out ***model.coef_[2]*** for the fitted model rounded to 2 decimal places?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Test Regression Model\n",
    "\n",
    "We would now like to test our regression model. This test should give the residual sum of squares, which for your convenience is written as\n",
    "$$\n",
    "RSS = \\sum_{i=1}^N (p_i - y_i)^2,\n",
    "$$\n",
    "where $p_i$ refers to the $i^{\\rm th}$ prediction made from `X_test`, $y_i$ refers to the $i^{\\rm th}$ value in `y_test`, and $N$ is the length of `y_test`.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a trained model and two `arrays` as input. This will be the `X_test` and `y_test` variables. \n",
    "* Should return the residual sum of squares over the input from the predicted values of `X_test` as compared to values of `y_test`.\n",
    "* The output should be a `float` rounded to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test, y_test):\n",
    "    \n",
    "    #your code here\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(np.sum((y_pred-y_test)**2))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882.300568198362\n"
     ]
    }
   ],
   "source": [
    "#Question 17\n",
    "test_model(reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17. What is the Residual Sum of Squares value for the fitted Linear Regression Model on the test set?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Train Decision Tree Regresson Model\n",
    "\n",
    "Let us try improve this accuracy by training a model using sklearn's `DecisionTreeRegressor` class with a random state value of 42. Write a function that will take as input `(X_train, y_train)` that we created previously, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `DecisionTreeRegressor` model with a random state value of 42.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dt_model(X_train, y_train):\n",
    "    \n",
    "    #your code here\n",
    "    global dt\n",
    "    dt = DecisionTreeRegressor(random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dt_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have trained your model, lets see how well it does on the test set. Use the test_reg_model function you previously created to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_err(predictions, y_test):\n",
    "    \n",
    "    #your code here\n",
    "    rss = np.sum(np.square(y_test - predictions))\n",
    "    print(rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882.300568198362\n"
     ]
    }
   ],
   "source": [
    "r_err(reg.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113.0\n"
     ]
    }
   ],
   "source": [
    "test_model(dt, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q18. What is the Residual Sum of Squares value for the fitted Decision Tree Regression Model on the test set?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 - Mean Absolute Error\n",
    "Write a function to compute the Mean Absolute Error (MAE), which is given by:\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{N} \\sum_{n=i}^N |p_i - y_i|\n",
    "$$\n",
    "\n",
    "where $p_i$ refers to the $i^{\\rm th}$ `prediction`, $y_i$ refers to the $i^{\\rm th}$ value in `y_test`, and $N$ is the length of `y_test`.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two `arrays` as input. You can think of these as the `predictions` and `y_test` variables you get when testing a model. \n",
    "* Should return the mean absolute error over the input from the predicted values of `X_test` as compared to values of `y_test`.\n",
    "* The output should be a `float` rounded to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_abs_err(predictions, y_test):\n",
    "    \n",
    "    #your code here\n",
    "    from sklearn import metrics\n",
    "    return metrics.mean_absolute_error(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.166666666666667\n"
     ]
    }
   ],
   "source": [
    "print(mean_abs_err(np.array([7.5,7,1.2]),np.array([3.2,2,-2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9. What is the result of printing out mean_abs_err(np.array([7.5,7,1.2]),np.array([3.2,2,-2]))?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.166666666666667\n"
     ]
    }
   ],
   "source": [
    "print(mean_abs_err(np.array([7.5,7,1.2]),np.array([3.2,2,-2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10. Which regression model (Linear vs DecisionTree) has the lowest Mean Absolute error?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48553846153846153"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_abs_err(dt.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5769367364597567"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_abs_err(reg.predict(X_test),y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
