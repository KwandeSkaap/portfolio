{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Coding Challenge 2: Pre-processing the Raw Titanic Dataset\n",
    "Â© Explore Data Science Academy\n",
    "\n",
    "\n",
    "Within the previous challenge, we began our journey towards creating a regression model capable of predicting the survivors of the historic sinking of the Titanic. \n",
    "\n",
    "For today's challenge, we expand upon this exploration by cleaning our data and performing feature engineering; ensuring that it is ready for use in various modelling strategies.  \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://i.kinja-img.com/gawker-media/image/upload/fhygjbyvm8rorm1uyg6s.jpg\"\n",
    "     alt=\"Barnicles on your ship :( \"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "Time to clean some ship data!\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Honour Code\n",
    "\n",
    "I **YOUR NAME**, **YOUR SURNAME**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Pre-requisites \n",
    "\n",
    "Before getting your hands dirty in this challenge (or erm... cleaning them), please ensure that the following steps have been taken:\n",
    "\n",
    " 1. You have completed _Regression Coding Challenge 1_. The coding challenges are designed to build upon one another, mimicking a process you will follow for most of your data science projects. \n",
    " \n",
    " 2. You have reviewed and are comfortable with the Titanic dataset contents. A further description of each field within the dataset can be found [here](https://www.kaggle.com/c/titanic/data)\n",
    " \n",
    "With these steps out of the way, we're ready to begin!\n",
    "\n",
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/regression_sprint/titanic_train_raw.csv')\n",
    "test_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/regression_sprint/titanic_test_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Handling Missing Data\n",
    "\n",
    "Having a comprehensive view of our dataset afforded by its exploration, we are ready to begin the first step of cleaning our data by considering cases of missing values.\n",
    "\n",
    "### Question 1.1: Removing Features\n",
    "\n",
    "In Question 1 of Challenge 1, we learnt that certain columns within our dataset had a high percentage of missing values. While there are numerous ways of handling such missing data, sometimes it is appropriate to discard them altogether. \n",
    "\n",
    "With this in mind, write a function called `drop_columns` which removes a column from a pandas dataframe if the percentage of missing values is greater than a given `threshold` value. Additionally, a user should also be able to provide a `unique_value_threshold` which removes a column if the percentage of unique values in that column is below the `unique_value_threshold`.    \n",
    "\n",
    "***Function arguments:***\n",
    " - `input_df` -> input `Pandas` DataFrame.\n",
    " - `threshold`-> python `float`, `threshhold` $\\in [0, 100.0]$.\n",
    " - `unique_value_threshold` -> python `float`, `unique_value_threshold` $\\in [0, 100.0]$.\n",
    "\n",
    "***Function Specifications:***\n",
    " - Name the function `drop_columns`\n",
    " - Must take any Pandas `DataFrame` as input and return a `DataFrame` as output.\n",
    " - Must remove one or more columns which exceed the drop `threshold`, as well as any columns whose percentage of unique values is below the `unique_value_threshold`. \n",
    " - If no columns exceed the `threshold` or have a unique value percentage less than `unique_value_threshold`, a dataframe identical to the input must be returned.  \n",
    " - **NaN values should be excluded when computing the percentage of unique values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def drop_columns(input_df, threshold, unique_value_threshold):\n",
    "    # your code here\n",
    "    output_df = input_df\n",
    "    holder = list(input_df.columns)\n",
    "    holder2 = []\n",
    "    for x in holder:\n",
    "        if ((input_df[x].isna().sum()/len(input_df[x]))*100 > threshold):\n",
    "            holder2.append(x)\n",
    "        elif ((input_df[x].nunique()/len(input_df[x]))*100< unique_value_threshold):\n",
    "            holder2.append(x)\n",
    "    output_df = output_df.drop(holder2, axis=1)\n",
    "    \n",
    "    return output_df\n",
    "        \n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drop_columns(train_df, 60, 0.5).columns == ['PassengerId', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "drop_columns(train_df, 60, 0.5).columns == ['PassengerId', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare']\n",
    "\n",
    "drop_columns(train_df, 80, 15).columns == ['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2: Data Imputation \n",
    "\n",
    "In Question 2 of Challenge 1, we saw that it is possible to replace or [impute](https://en.wikipedia.org/wiki/Imputation_(statistics)) missing data based on simple population statistics such as the mean, median or mode of the targeted feature.\n",
    "\n",
    "When a friend of yours hears that you are imputing the `'Age'` column by simply taking the *mean* or *median* of the non-missing data, she decides to show-off the following code which produces two telling plots:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxenplot(train_df['Pclass'], train_df['Age'], hue=train_df['Survived'])\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxenplot(train_df['Sex'], train_df['Age'], hue=train_df['Survived'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(train_df, row='Pclass', col='Sex', height=2.0, aspect=3.0)\n",
    "grid.map(plt.hist, 'Age', bins=30)\n",
    "grid.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these plots, your friend argues that there are correlations between the `'Pclass'`, `'Sex'` and `'Age'` features within the dataset, and that `'Age'` shows influence in predicting a given passenger's survival. \n",
    "\n",
    "Aware of this new knowledge, you decide to create a function, `conditional_impute`, which performs imputation upon an `age` column within a Pandas `DataFrame` based upon both `Sex` and `Pclass` columns. Given that you are uncertain which statistic best models your data, you decide to once again to add a `choice` parameter which allows either the *mean* or *median* to be used for imputing the data.   \n",
    "\n",
    "***Function arguments:***\n",
    " - `input_df` -> input `Pandas` DataFrame. \n",
    " - `choice`-> Python `string` of either `'mean'` or `'median'`. Default is `'median'`. \n",
    "\n",
    "***Function Specifications:***\n",
    " - Name the function `conditional_impute`\n",
    " - Must take a Pandas `DataFrame` as input and return a `DataFrame` as output.\n",
    " - Should impute `Age` values based upon the descriptive statistic method specified by `choice`.\n",
    " - Round all imputed answers to 1 decimal point. \n",
    " - If `choice` is not either `'mean'` or `'median'`,  a `ValueError` must be raised.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def conditional_impute(input_df, choice='median'):\n",
    "    # your code here\n",
    "    output_df = input_df\n",
    "    missing = output_df[output_df['Age'].isnull()]\n",
    "    meaner = output_df.groupby(['Sex','Pclass'])['Age'].mean()\n",
    "    medianer = output_df.groupby(['Sex','Pclass'])['Age'].median()\n",
    "    def fill_missing_mean(row):\n",
    "        if pd.isnull(row['Age']):\n",
    "            return meaner[row['Sex'],row['Pclass']]\n",
    "        else:\n",
    "            return row['Age']\n",
    "    def fill_missing_median(row):\n",
    "        if pd.isnull(row['Age']):\n",
    "            return medianer[row['Sex'],row['Pclass']]\n",
    "        else:\n",
    "            return row['Age']\n",
    "    \n",
    "    if choice == 'mean':\n",
    "        output_df['Age'] =output_df.apply(fill_missing_mean, axis=1)\n",
    "    elif choice == 'median':\n",
    "        output_df['Age'] =output_df.apply(fill_missing_median, axis=1)\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    return output_df\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_impute(train_df, choice='mean')[['Name','Age']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "conditional_impute(train_df, choice='median')[['Name','Age']].tail()\n",
    "\n",
    "```\n",
    "\n",
    "><table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>Name</th>      <th>Age</th>    </tr>  </thead>  <tbody>    <tr>      <th>886</th>      <td>Montvila, Rev. Juozas</td>      <td>27.0</td>    </tr>    <tr>      <th>887</th>      <td>Graham, Miss. Margaret Edith</td>      <td>19.0</td>    </tr>    <tr>      <th>888</th>      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>      <td>21.5</td>    </tr>    <tr>      <th>889</th>      <td>Behr, Mr. Karl Howell</td>      <td>26.0</td>    </tr>    <tr>      <th>890</th>      <td>Dooley, Mr. Patrick</td>      <td>32.0</td>    </tr>  </tbody></table>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "```python\n",
    "conditional_impute(train_df, choice='mean')[['Name','Age']].tail()\n",
    "```\n",
    "\n",
    "> <table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>Name</th>      <th>Age</th>    </tr>  </thead>  <tbody>    <tr>      <th>886</th>      <td>Montvila, Rev. Juozas</td>      <td>27.0</td>    </tr>    <tr>      <th>887</th>      <td>Graham, Miss. Margaret Edith</td>      <td>19.0</td>    </tr>    <tr>      <th>888</th>      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>      <td>21.8</td>    </tr>    <tr>      <th>889</th>      <td>Behr, Mr. Karl Howell</td>      <td>26.0</td>    </tr>    <tr>      <th>890</th>      <td>Dooley, Mr. Patrick</td>      <td>32.0</td>    </tr>  </tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Feature Engineering \n",
    "\n",
    "Having considered missing data, we can now further prepare our dataset for use within a model by performing feature engineering.\n",
    "\n",
    "### Question 2.1: What's in a name?\n",
    "\n",
    "When you originally received the titanic dataset, you were excited to see the `Name` feature included, as you believed this might be another source of information to help infer a person's social status on the ship. To use this feature however, we need to extract an individual's _title_ from his/her name, as calling `train_df['Name'].unique().shape` tells us that every `Name` entry within our train dataset is currently unique. \n",
    "\n",
    "Go ahead and perform this transformation by writing a function called `extract_title`, which adds an extra `Title` column to our dataframe into which is placed a person's given title found within the `Name` column. \n",
    "\n",
    "Examples of title extraction; \n",
    " - `Braund, Mr. Owen Harris` maps to a title of `Mr.`\n",
    " - `Heikkinen, Miss. Laina` maps to a title of `Miss.`\n",
    "\n",
    "***Function arguments:***\n",
    " - `input_df` -> input `Pandas` DataFrame.\n",
    "\n",
    "***Function specifications:***\n",
    " - Name the function `extract_title`\n",
    " - Must take any Pandas `DataFrame` as input and return a `DataFrame` as output with an additional `Title` column.\n",
    " - Assume that `input_df` represents a DataFrame possessing a `'Name'` column, with each corresponding row entry being a `string`-based name containing exactly one title. \n",
    " - Assume that a title is represented by a word with two or more characters ending in a `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def extract_title(input_df):\n",
    "    # your code here\n",
    "    output_df = input_df.copy()\n",
    "    \n",
    "    output_df['Name_hold'] = output_df['Name'].str.split()\n",
    "    index = output_df.index\n",
    "    for x in index:\n",
    "        title = output_df.at[x, 'Name_hold']\n",
    "        for y in title:\n",
    "            if y[-1] == '.' && len(y) >=3:\n",
    "                output_df.at[x, 'Title'] = y\n",
    "    return output_df\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_title(train_df)['Title'].unique() == ['Mr.', 'Mrs.', 'Miss.', 'Master.',\n",
    "                                              'Don.', 'Rev.', 'Dr.', 'Mme.','Ms.',\n",
    "                                              'Major.', 'Lady.', 'Sir.', 'Mlle.',\n",
    "                                              'Col.', 'Capt.','Countess.', 'Jonkheer.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "\n",
    "extract_title(train_df)['Title'].unique() == ['Mr.', 'Mrs.', 'Miss.', 'Master.',\n",
    "                                              'Don.', 'Rev.', 'Dr.', 'Mme.','Ms.',\n",
    "                                              'Major.', 'Lady.', 'Sir.', 'Mlle.',\n",
    "                                              'Col.', 'Capt.','Countess.', 'Jonkheer.']\n",
    "\n",
    "\n",
    "extract_title(test_df)['Title'].unique() == ['Mr.', 'Mrs.', 'Miss.', 'Master.', \n",
    "                                             'Ms.', 'Col.', 'Rev.', 'Dr.','Dona.']\n",
    "\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2: Feature Selection\n",
    "\n",
    "Having your `'Title'` column prepared, you perform a quick examination to see the distribution of its categories with relation to the gender of a passenger.\n",
    "\n",
    "(***Note:*** Even if you weren't able to solve Q2.1, *we have imported the correct dataframe*, `title_df` in the code section beneath for your continued use.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the correct form of the train.csv for Q 2.2\n",
    "title_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/regression_sprint/titanic_train_title.csv')\n",
    "pd.crosstab(index=title_df['Title'], columns=title_df['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this observation, you realise that a just small group of categories represent a considerable majority of datapoints within the column. Using this outcome in your favour, you decide to only preserve the more common titles and to group the remaining items into a single category called `'Uncommon'`. \n",
    "\n",
    "\n",
    "To accomplish your objective, write a function called `group_titles` which takes in your dataframe containing the `Title` column, along with a selection of `uncommon_titles`, and returns the dataframe with the modified `Title` column in which the updated groupings are reflected.\n",
    "\n",
    "***Function arguments:***\n",
    " - `input_df` -> input `Pandas` DataFrame.\n",
    " - `uncommon_titles` -> A 1-D `list` of Python `strings` representing the categories of titles to be grouped into the `\"Uncommon\"` category. \n",
    "***Function specifications:***\n",
    " - Name the function `group_titles`\n",
    " - Must take any Pandas `DataFrame` as input and return a `DataFrame` with the `Title` column containing newly regrouped categories.\n",
    " - Assume that `input_df` represents a DataFrame possessing a `'Title'` column, with each corresponding row entry being a `string`-based title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def group_titles(input_df, uncommon_titles):\n",
    "    # your code here\n",
    "    output_df = input_df\n",
    "    for x in uncommon_titles:\n",
    "        output_df['Title'] = output_df['Title'].replace(x, 'Uncommon')\n",
    "    \n",
    "    return output_df\n",
    "    \n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncommon_titles = ['Don.', 'Rev.', 'Mme.','Major.', 'Sir.', 'Mlle.','Countess.', 'Jonkheer.']\n",
    "group_titles(title_df, uncommon_titles=['Don.', 'Rev.', 'Mme.','Major.', 'Sir.', 'Mlle.','Countess.', 'Jonkheer.'])['Title'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "group_titles(title_df, uncommon_titles=['Don.', 'Rev.', 'Mme.','Major.', 'Sir.', 'Mlle.','Countess.', 'Jonkheer.'])['Title'].unique() == \n",
    "['Mr.', 'Mrs.', 'Miss.', 'Master.', 'Uncommon', 'Dr.', 'Ms.',\n",
    "       'Lady.', 'Col.', 'Capt.']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3: Feature Encoding\n",
    "\n",
    "Finally, you further decide that it's time to encode your new categorical features within the `'Title'` column using [dummy variables.](https://en.wikipedia.org/wiki/Dummy_variable_(statistics)) \n",
    "\n",
    "Write a function called `encode_titles` which encodes the various categories contained within the `Title` column of an input DataFrame as numerically-based dummy variables. \n",
    "\n",
    "***Function arguments:***\n",
    " - `input_df` -> input `Pandas` DataFrame.\n",
    "\n",
    "***Function specifications:***\n",
    " - Name the function `encode_titles`\n",
    " - Must take any Pandas `DataFrame` as input and return a `DataFrame` as output with an expanded set of columns representing dummy variables corresponding to the newly regrouped `Title` categories.\n",
    " - Assume that `input_df` represents a DataFrame possessing a `'Title'` column, with each corresponding row entry being a `string`-based title. \n",
    " - **NB!** Ensure that your dummy encoding avoids the [dummy variable trap](https://stattrek.com/multiple-regression/dummy-variables.aspx). As a ***hint***, look at the documentation for the Pandas [get_dummies()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) function.\n",
    "\n",
    "(***Note:*** Even if you weren't able to solve Q2.2, *we have imported the correct dataframe*, `title_regrouped_df` in the code section beneath for your continued use.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the correct form of the train.csv for Q 2.2\n",
    "title_regrouped_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/regression_sprint/titanic_train_title_regrouped.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def dummy_encode_titles(input_df):\n",
    "    # your code here\n",
    "    return pd.get_dummies(input_df, drop_first=True)\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encode_df = dummy_encode_titles(title_regrouped_df)\n",
    "dummy_cols = [col for col in encode_df if col.startswith('Title')]\n",
    "encode_df[dummy_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "encode_df = dummy_encode_titles(title_regrouped_df)\n",
    "dummy_cols = [col for col in encode_df if col.startswith('Title')]\n",
    "encode_df[dummy_cols].head()\n",
    "```\n",
    "\n",
    "><table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>Title_Miss.</th>      <th>Title_Mr.</th>      <th>Title_Mrs.</th>      <th>Title_Uncommon</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>2</th>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>  </tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
